{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "! pip install langchain_community pandas huggingface_hub chromadb==0.4.14 langchain-huggingface langchain_groq lark openai gradio python-dotenv qrcode SpeechRecognition gTTS sounddevice soundfile google-cloud-texttospeech PyAudio"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T15:33:59.451485Z",
          "start_time": "2024-06-10T15:33:51.252837Z"
        },
        "id": "16b49d591050a7a9",
        "outputId": "c33373a3-be80-4c62-d0a1-a628260d9e7c"
      },
      "id": "16b49d591050a7a9",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain_community in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (0.2.3)\n",
            "Requirement already satisfied: pandas in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (1.5.3)\n",
            "Requirement already satisfied: huggingface_hub in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (0.23.0)\n",
            "Requirement already satisfied: chromadb in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (0.5.0)\n",
            "Requirement already satisfied: langchain-huggingface in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (0.0.3)\n",
            "Requirement already satisfied: langchain_groq in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (0.1.5)\n",
            "Requirement already satisfied: lark in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (1.1.9)\n",
            "Requirement already satisfied: openai in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (1.33.0)\n",
            "Requirement already satisfied: gradio in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (4.33.0)\n",
            "Requirement already satisfied: python-dotenv in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (1.0.1)\n",
            "Requirement already satisfied: PyYAML>=5.3 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain_community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain_community) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain_community) (3.9.5)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain_community) (0.6.6)\n",
            "Requirement already satisfied: langchain<0.3.0,>=0.2.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain_community) (0.2.2)\n",
            "Requirement already satisfied: langchain-core<0.3.0,>=0.2.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain_community) (0.2.4)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain_community) (0.1.74)\n",
            "Requirement already satisfied: numpy<2,>=1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain_community) (1.24.3)\n",
            "Requirement already satisfied: requests<3,>=2 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain_community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain_community) (8.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from pandas) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from pandas) (2024.1)\n",
            "Requirement already satisfied: filelock in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from huggingface_hub) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from huggingface_hub) (2024.3.1)\n",
            "Requirement already satisfied: packaging>=20.9 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from huggingface_hub) (23.2)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from huggingface_hub) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from huggingface_hub) (4.11.0)\n",
            "Requirement already satisfied: build>=1.0.3 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (1.2.1)\n",
            "Requirement already satisfied: pydantic>=1.9 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (2.7.1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (0.111.0)\n",
            "Requirement already satisfied: uvicorn>=0.18.3 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.30.1)\n",
            "Requirement already satisfied: posthog>=2.4.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (3.5.0)\n",
            "Requirement already satisfied: onnxruntime>=1.14.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (1.18.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (1.25.0)\n",
            "Requirement already satisfied: tokenizers>=0.13.2 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (0.19.1)\n",
            "Requirement already satisfied: pypika>=0.48.9 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (7.4.0)\n",
            "Requirement already satisfied: importlib-resources in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (6.1.1)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (1.64.1)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (4.1.3)\n",
            "Requirement already satisfied: typer>=0.9.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (0.12.3)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (30.1.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (3.10.3)\n",
            "Requirement already satisfied: graphlib-backport>=1.0.3 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from chromadb) (1.1.0)\n",
            "Requirement already satisfied: sentence-transformers>=2.6.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain-huggingface) (3.0.1)\n",
            "Requirement already satisfied: transformers>=4.39.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain-huggingface) (4.41.2)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain_groq) (0.5.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from openai) (4.2.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (5.3.0)\n",
            "Requirement already satisfied: ffmpy in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (0.3.0)\n",
            "Requirement already satisfied: gradio-client==0.17.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (0.17.0)\n",
            "Requirement already satisfied: jinja2<4.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (2.1.3)\n",
            "Requirement already satisfied: matplotlib~=3.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (3.7.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (10.3.0)\n",
            "Requirement already satisfied: pydub in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: ruff>=0.2.2 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (0.4.8)\n",
            "Requirement already satisfied: semantic-version~=2.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: urllib3~=2.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio) (2.2.1)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from gradio-client==0.17.0->gradio) (11.0.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: idna>=2.8 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.2 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: pyproject_hooks in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from build>=1.0.3->chromadb) (1.1.0)\n",
            "Requirement already satisfied: colorama in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
            "Requirement already satisfied: importlib-metadata>=4.6 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from build>=1.0.3->chromadb) (7.0.1)\n",
            "Requirement already satisfied: tomli>=1.1.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.37.2)\n",
            "Requirement already satisfied: fastapi-cli>=0.0.2 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (0.0.4)\n",
            "Requirement already satisfied: ujson!=4.0.2,!=4.1.0,!=4.2.0,!=4.3.0,!=5.0.0,!=5.1.0,>=4.0.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (5.10.0)\n",
            "Requirement already satisfied: email_validator>=2.0.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from fastapi>=0.95.2->chromadb) (2.1.1)\n",
            "Requirement already satisfied: certifi in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: zipp>=3.1.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from importlib-resources->chromadb) (3.17.0)\n",
            "Requirement already satisfied: six>=1.9.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.30.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (0.58.0)\n",
            "Requirement already satisfied: requests-oauthlib in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
            "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain<0.3.0,>=0.2.0->langchain_community) (0.2.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from langchain-core<0.3.0,>=0.2.0->langchain_community) (1.33)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from matplotlib~=3.0->gradio) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from matplotlib~=3.0->gradio) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from matplotlib~=3.0->gradio) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from matplotlib~=3.0->gradio) (3.0.9)\n",
            "Requirement already satisfied: coloredlogs in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.3.25)\n",
            "Requirement already satisfied: protobuf in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (4.25.3)\n",
            "Requirement already satisfied: sympy in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
            "Requirement already satisfied: deprecated>=1.2.6 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.14)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.63.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.25.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.25.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.25.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.46b0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.46b0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.46b0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.46b0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.46b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (69.5.1)\n",
            "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from opentelemetry-instrumentation==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.16.0)\n",
            "Requirement already satisfied: asgiref~=3.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from opentelemetry-instrumentation-asgi==0.46b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
            "Requirement already satisfied: backoff>=1.10.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from pydantic>=1.9->chromadb) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from pydantic>=1.9->chromadb) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
            "Requirement already satisfied: torch>=1.11.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.3.2)\n",
            "Requirement already satisfied: scipy in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain-huggingface) (1.10.1)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from transformers>=4.39.0->langchain-huggingface) (0.4.3)\n",
            "Requirement already satisfied: click>=8.0.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from typer>=0.9.0->chromadb) (13.7.1)\n",
            "Requirement already satisfied: httptools>=0.5.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.1)\n",
            "Requirement already satisfied: watchfiles>=0.13 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.22.0)\n",
            "Requirement already satisfied: dnspython>=2.0.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from email_validator>=2.0.0->fastapi>=0.95.2->chromadb) (2.6.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.0->langchain_community) (2.4)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.7.1)\n",
            "Requirement already satisfied: pkgutil-resolve-name>=1.3.10 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (1.3.10)\n",
            "Requirement already satisfied: referencing>=0.28.4 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.30.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.10.6)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from rich>=10.11.0->typer>=0.9.0->chromadb) (2.15.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain-huggingface) (3.5.0)\n",
            "Requirement already satisfied: mpmath>=0.19 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
            "Requirement already satisfied: pyreadline3 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.4.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer>=0.9.0->chromadb) (0.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in d:\\toolkit\\conda\\envs\\envx\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.0)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:09:03.325899Z",
          "start_time": "2024-06-10T16:09:03.316902Z"
        },
        "id": "6aec111842e19bd8"
      },
      "id": "6aec111842e19bd8",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## const variables definition\n",
        "define all const values like API keys, paths, etc"
      ],
      "metadata": {
        "collapsed": false,
        "id": "cacef934746f2bf0"
      },
      "id": "cacef934746f2bf0"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:09:04.892238Z",
          "start_time": "2024-06-10T16:09:04.871242Z"
        },
        "id": "d9e344d4c00cda5d"
      },
      "cell_type": "code",
      "source": [
        "def get_key(key,required=True):\n",
        "    try:\n",
        "        from google.colab.userdata import get as getenv\n",
        "    except ImportError:\n",
        "        from os import getenv\n",
        "        import dotenv\n",
        "        dotenv.load_dotenv()\n",
        "\n",
        "    value = getenv(key)\n",
        "\n",
        "    if not value:\n",
        "        value = input(f\"Please enter the value for {key}:\")\n",
        "        if value == \"\" and required:\n",
        "            raise ValueError(f\"Value for {key} is required\")\n",
        "\n",
        "    return value"
      ],
      "id": "d9e344d4c00cda5d",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# tokens and API\n",
        "huggingface_token = get_key(\"HUGGINGFACE_KEY\")\n",
        "groq_api_key = get_key(\"GROQ_KEY\")\n",
        "\n",
        "# dirs\n",
        "DATA_DIR = './data'\n",
        "persist_directory = DATA_DIR+\"/chroma_db\"\n",
        "embedding_cache_directory = DATA_DIR+\"/embedding_cache\"\n",
        "USER_AGENT=\"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/122.0.0.0 YaBrowser/24.4.0.0 Safari/537.36\""
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:09:06.973773Z",
          "start_time": "2024-06-10T16:09:06.964773Z"
        },
        "id": "c4ce04d766b3f573"
      },
      "id": "c4ce04d766b3f573",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import login\n",
        "login(token=huggingface_token)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:09:08.872775Z",
          "start_time": "2024-06-10T16:09:08.068778Z"
        },
        "id": "e946e57c3c144635",
        "outputId": "3dd51330-1632-4ff5-eabf-963de10a6211"
      },
      "id": "e946e57c3c144635",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to C:\\Users\\Sina\\.cache\\huggingface\\token\n",
            "Login successful\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load Documents\n",
        "Try to load the documents from the datasets\n",
        "* Course Degree Dataset (cvs)\n",
        "* Course Unit Dataset (cvs)\n",
        "* spelling out the dataset's columns (txt)\n",
        "* Identity (txt)\n",
        "* general information about the university and services (Web)"
      ],
      "metadata": {
        "collapsed": false,
        "id": "d22d261849e6ba48"
      },
      "id": "d22d261849e6ba48"
    },
    {
      "cell_type": "code",
      "source": [
        "def get_course_unit_content(course_unit):\n",
        "    course_code = course_unit['course_unit_code']\n",
        "    course_name = course_unit['course_unit_name']\n",
        "    course_degree_code = course_unit['course_degree_code']\n",
        "    course_degree_name = course_unit['course_degree_name']\n",
        "    cycle = \" \".join(course_unit['degree_course'].split(' ')[0:2])\n",
        "    academic_year = course_unit['course_unit_academic_year']\n",
        "    credits = course_unit['number_of_ects_credits_allocated']\n",
        "    language = course_unit['language_of_instruction']\n",
        "    assessment_type = course_unit['type_of_assessment']\n",
        "    department = course_unit['department_of_reference']\n",
        "    mandatory_attendance = {\"Yes\": \"required\", \"No\": \"not required\", \"Not mentioned.\": \"not mentioned\"}[\n",
        "        course_unit['mandatory_attendance']]\n",
        "    single_course_possible = False if \"CANNOT\" in course_unit['single_course_unit'] else True\n",
        "    optional_course_possible = False if \"CANNOT\" in course_unit['optional_course_unit'] else True\n",
        "    erasmus_course_possible = False if \"CANNOT\" in course_unit['course_unit_for_erasmus_students'] else True\n",
        "    lecturer = course_unit['course_unit_lecturer']\n",
        "    semester = course_unit['course_unit_organization_period']\n",
        "    year = course_unit['course_unit_organization_year']\n",
        "    teaching_method = course_unit['course_unit_organization_teaching_method']\n",
        "    teaching_hours = course_unit['course_unit_organization_teachinghours']\n",
        "    hours_of_individual_study = course_unit['course_unit_organization_hours_ofindividual_study']\n",
        "    start_date = course_unit['start_of_activities']\n",
        "    end_date = course_unit['end_of_activities']\n",
        "    url = course_unit['course_unit_url']\n",
        "    prerequisites = course_unit['prerequisites']\n",
        "    target_skills_and_knowledge = course_unit['target_skills_and_knowledge']\n",
        "    examination_methods = course_unit['examination_methods']\n",
        "    assessment = course_unit['assessment_criteria']\n",
        "    course_unit_contents = course_unit['course_unit_contents']\n",
        "    planned_learning_activities_and_teaching_methods = course_unit['planned_learning_activities_and_teaching_methods']\n",
        "    additional_notes_and_resources = course_unit['additional_notes_about_suggested_reading']\n",
        "    text_books_and_resources = course_unit['textbooks_(and_optional_supplementary_readings)']\n",
        "\n",
        "    content = f\"\"\"\n",
        "    The course unit code {course_code}, part of the {cycle} in {course_degree_name} (course degree code {course_degree_code}), titled \"{course_name}\" is scheduled for the academic year {academic_year}.It allocates {credits} ECTS credits and employs a {assessment_type} type of assessment. The language of instruction is {language}, mandatory attendance {mandatory_attendance}. The course is held by the {department}, taught (teacher/lecturer) by {lecturer} in the {semester} of the {year} through {teaching_method} lectures totaling {teaching_hours} teaching hours and {hours_of_individual_study} hours of individual study. The course starts on {start_date} and ends on {end_date}, with further details available at the provided course URL [{url}]. The course unit {\"can\" if single_course_possible else \"can not\"} be attended as a single course unit, and {\"can\" if optional_course_possible else \"Can not\"} be chosen as an optional course unit, and is {\"\" if erasmus_course_possible else \"Not \"}open to Erasmus+ and other exchange students. \\n Prerequisites fot this course is: {prerequisites} \\n Target skills and knowledge for this course is: {target_skills_and_knowledge}. Assessment criteria is {assessment} for this course and also examination (test) methods are :{examination_methods} Course unit contents (what strudent learns from this course) are: {course_unit_contents} . Planned learning activities and teaching methods are : {planned_learning_activities_and_teaching_methods}. Additional notes and resource about suggested reading: {additional_notes_and_resources}. Textbooks for this course that suggested by teacher are(and optional supplementary readings): {text_books_and_resources}\n",
        "    \"\"\"\n",
        "    return content.strip()\n",
        "\n",
        "\n",
        "def rename_columns(df, target_column_name, new_name):\n",
        "    return df.rename(columns={target_column_name: new_name})\n"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:09:09.642097Z",
          "start_time": "2024-06-10T16:09:09.617099Z"
        },
        "id": "aa49d72c631f760e"
      },
      "id": "aa49d72c631f760e",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "course_degree_df = pd.read_csv(DATA_DIR + '/degree_courses.csv')\n",
        "course_unit_df = pd.read_csv(DATA_DIR + '/course_units.csv')\n",
        "\n",
        "\n",
        "def getRowContent(columns, row) -> str:\n",
        "    def convertToFormattedText(value):\n",
        "        return value.replace('_', ' ').capitalize()\n",
        "    return '\\n'.join(f\"{convertToFormattedText(key)} = {row[key]}\" for key in columns)\n",
        "\n",
        "\n",
        "def load_degree_courses_dataframe(course_degree_df=course_degree_df, course_unit_df=course_unit_df):\n",
        "    course_degree_df = course_degree_df[['degree_course_code'] + [col for col in course_degree_df.columns if col != 'degree_course_code']]\n",
        "\n",
        "    # drop [\"classes_(ministerial_field_of_study_codes)\",\"degree_issued\",\"intra-university_with\"] columns\n",
        "    course_degree_df = course_degree_df.drop(columns=['classes_(ministerial_field_of_study_codes)', 'degree_issued', 'intra-university_with'])\n",
        "\n",
        "    course_degree_df['school_of'] = 'Science'\n",
        "    course_degree_df['course_units'] = course_degree_df['degree_course_code'].apply(lambda x: course_unit_df[course_unit_df['course_degree_code'] == x]['course_unit_name'].tolist())\n",
        "    course_degree_df['course_units'] = course_degree_df['course_units'].apply(lambda x: ', '.join(x))\n",
        "    course_degree_df['content'] = course_degree_df.apply(lambda x: getRowContent(course_degree_df, x), axis=1)\n",
        "    metadata = ['degree_course_code', 'degree_title', 'school_of', 'course_units', 'content']\n",
        "\n",
        "    return course_degree_df[metadata]\n",
        "\n",
        "\n",
        "def load_units_document_dataframe(course_degree_df=course_degree_df, course_unit_df=course_unit_df):\n",
        "    # Let's load the course degree dataset\n",
        "    course_unit_df = course_unit_df.drop(columns=['branch'])\n",
        "    course_unit_df['course_degree_name'] = course_unit_df['course_degree_code'].apply(lambda x: course_degree_df[course_degree_df['degree_course_code'] == x]['degree_title'].values[0])\n",
        "    course_unit_df['content'] = course_unit_df.apply(lambda x: get_course_unit_content(x), axis=1)\n",
        "    course_unit_df['course_unit_name'] = course_unit_df['course_unit_name'].apply(lambda x: x.title())\n",
        "    # keep these columns as metadata\n",
        "    course_unit_df = course_unit_df[[\"course_unit_code\", \"course_degree_code\", \"course_unit_name\", \"course_degree_name\",\"course_unit_lecturer\", \"content\"]]\n",
        "    return course_unit_df\n",
        "\n",
        "\n",
        "df = load_units_document_dataframe()\n",
        "df"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:09:41.795363Z",
          "start_time": "2024-06-10T16:09:41.246355Z"
        },
        "id": "670041ca12d0855c",
        "outputId": "6d387fbf-f53f-4fb2-c1f1-f6d00213301e"
      },
      "id": "670041ca12d0855c",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "    course_unit_code course_degree_code  \\\n",
              "0         SCP9086382             SC2490   \n",
              "1         SCQ0093339             SC2490   \n",
              "2         SCQ0093338             SC2490   \n",
              "3         SCP9086381             SC2490   \n",
              "4         SCP9086380             SC2490   \n",
              "..               ...                ...   \n",
              "747       SCQ1095738             SC2590   \n",
              "748       SCQ1095721             SC2590   \n",
              "749       SCQ1095722             SC2590   \n",
              "750       SCQ2101040             SC2590   \n",
              "751       SCQ1095596             SC2590   \n",
              "\n",
              "                                      course_unit_name  \\\n",
              "0                                Advanced Astrophysics   \n",
              "1    Astrophysics Laboratory 1: High Energy Instrum...   \n",
              "2    Astrophysics Laboratory 1: Infrared And Optica...   \n",
              "3           Fundamentals Of Astrophysics And Cosmology   \n",
              "4                       Fundamentals Of Modern Physics   \n",
              "..                                                 ...   \n",
              "747         Health And Environment In Circular Economy   \n",
              "748  Psychology, Policy Making And Education To A C...   \n",
              "749       Understanding Statistics Of Circular Economy   \n",
              "750                     Circular Economy Summer School   \n",
              "751                                         Final Exam   \n",
              "\n",
              "                                    course_degree_name  \\\n",
              "0                           Astrophysics And Cosmology   \n",
              "1                           Astrophysics And Cosmology   \n",
              "2                           Astrophysics And Cosmology   \n",
              "3                           Astrophysics And Cosmology   \n",
              "4                           Astrophysics And Cosmology   \n",
              "..                                                 ...   \n",
              "747  Sustainable Chemistry And Technologies For Cir...   \n",
              "748  Sustainable Chemistry And Technologies For Cir...   \n",
              "749  Sustainable Chemistry And Technologies For Cir...   \n",
              "750  Sustainable Chemistry And Technologies For Cir...   \n",
              "751  Sustainable Chemistry And Technologies For Cir...   \n",
              "\n",
              "                course_unit_lecturer  \\\n",
              "0                  MICHELE TRABUCCHI   \n",
              "1                      STEFANO CIROI   \n",
              "2                  ROBERTO RAGAZZONI   \n",
              "3                   SABINO MATARRESE   \n",
              "4                    CHIARA MAURIZIO   \n",
              "..                               ...   \n",
              "747          FAZEL ABDOLAHPUR MONIKH   \n",
              "748  ENRICO RUBALTELLI and MAJA ROCH   \n",
              "749                  FRANCESCA BASSI   \n",
              "750                     SILVIA GROSS   \n",
              "751                   Not mentioned.   \n",
              "\n",
              "                                               content  \n",
              "0    The course unit code SCP9086382, part of the S...  \n",
              "1    The course unit code SCQ0093339, part of the S...  \n",
              "2    The course unit code SCQ0093338, part of the S...  \n",
              "3    The course unit code SCP9086381, part of the S...  \n",
              "4    The course unit code SCP9086380, part of the S...  \n",
              "..                                                 ...  \n",
              "747  The course unit code SCQ1095738, part of the S...  \n",
              "748  The course unit code SCQ1095721, part of the S...  \n",
              "749  The course unit code SCQ1095722, part of the S...  \n",
              "750  The course unit code SCQ2101040, part of the S...  \n",
              "751  The course unit code SCQ1095596, part of the S...  \n",
              "\n",
              "[752 rows x 6 columns]"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>course_unit_code</th>\n",
              "      <th>course_degree_code</th>\n",
              "      <th>course_unit_name</th>\n",
              "      <th>course_degree_name</th>\n",
              "      <th>course_unit_lecturer</th>\n",
              "      <th>content</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>SCP9086382</td>\n",
              "      <td>SC2490</td>\n",
              "      <td>Advanced Astrophysics</td>\n",
              "      <td>Astrophysics And Cosmology</td>\n",
              "      <td>MICHELE TRABUCCHI</td>\n",
              "      <td>The course unit code SCP9086382, part of the S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SCQ0093339</td>\n",
              "      <td>SC2490</td>\n",
              "      <td>Astrophysics Laboratory 1: High Energy Instrum...</td>\n",
              "      <td>Astrophysics And Cosmology</td>\n",
              "      <td>STEFANO CIROI</td>\n",
              "      <td>The course unit code SCQ0093339, part of the S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>SCQ0093338</td>\n",
              "      <td>SC2490</td>\n",
              "      <td>Astrophysics Laboratory 1: Infrared And Optica...</td>\n",
              "      <td>Astrophysics And Cosmology</td>\n",
              "      <td>ROBERTO RAGAZZONI</td>\n",
              "      <td>The course unit code SCQ0093338, part of the S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SCP9086381</td>\n",
              "      <td>SC2490</td>\n",
              "      <td>Fundamentals Of Astrophysics And Cosmology</td>\n",
              "      <td>Astrophysics And Cosmology</td>\n",
              "      <td>SABINO MATARRESE</td>\n",
              "      <td>The course unit code SCP9086381, part of the S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>SCP9086380</td>\n",
              "      <td>SC2490</td>\n",
              "      <td>Fundamentals Of Modern Physics</td>\n",
              "      <td>Astrophysics And Cosmology</td>\n",
              "      <td>CHIARA MAURIZIO</td>\n",
              "      <td>The course unit code SCP9086380, part of the S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>747</th>\n",
              "      <td>SCQ1095738</td>\n",
              "      <td>SC2590</td>\n",
              "      <td>Health And Environment In Circular Economy</td>\n",
              "      <td>Sustainable Chemistry And Technologies For Cir...</td>\n",
              "      <td>FAZEL ABDOLAHPUR MONIKH</td>\n",
              "      <td>The course unit code SCQ1095738, part of the S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>748</th>\n",
              "      <td>SCQ1095721</td>\n",
              "      <td>SC2590</td>\n",
              "      <td>Psychology, Policy Making And Education To A C...</td>\n",
              "      <td>Sustainable Chemistry And Technologies For Cir...</td>\n",
              "      <td>ENRICO RUBALTELLI and MAJA ROCH</td>\n",
              "      <td>The course unit code SCQ1095721, part of the S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>749</th>\n",
              "      <td>SCQ1095722</td>\n",
              "      <td>SC2590</td>\n",
              "      <td>Understanding Statistics Of Circular Economy</td>\n",
              "      <td>Sustainable Chemistry And Technologies For Cir...</td>\n",
              "      <td>FRANCESCA BASSI</td>\n",
              "      <td>The course unit code SCQ1095722, part of the S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>750</th>\n",
              "      <td>SCQ2101040</td>\n",
              "      <td>SC2590</td>\n",
              "      <td>Circular Economy Summer School</td>\n",
              "      <td>Sustainable Chemistry And Technologies For Cir...</td>\n",
              "      <td>SILVIA GROSS</td>\n",
              "      <td>The course unit code SCQ2101040, part of the S...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>751</th>\n",
              "      <td>SCQ1095596</td>\n",
              "      <td>SC2590</td>\n",
              "      <td>Final Exam</td>\n",
              "      <td>Sustainable Chemistry And Technologies For Cir...</td>\n",
              "      <td>Not mentioned.</td>\n",
              "      <td>The course unit code SCQ1095596, part of the S...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>752 rows × 6 columns</p>\n",
              "</div>"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_community.document_loaders import TextLoader\n",
        "from langchain_community.document_loaders.merge import MergedDataLoader\n",
        "from langchain_community.document_loaders.dataframe import DataFrameLoader\n",
        "import bs4\n",
        "\n",
        "# Let's tell Identity document\n",
        "identity = TextLoader(DATA_DIR + '/identity.txt')\n",
        "\n",
        "meta_guide = TextLoader(DATA_DIR + '/meta_descriptions.txt')\n",
        "\n",
        "# Let's load help desk and other services\n",
        "webDocs = WebBaseLoader(\n",
        "    ['https://www.unipd.it/en/desks-and-contacts'],\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"centercolumn\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "\n",
        "# let's load the course and degree documents\n",
        "course_degree_df = DataFrameLoader(load_degree_courses_dataframe(), 'content')\n",
        "course_unit_df = DataFrameLoader(load_units_document_dataframe(), 'content')\n",
        "\n",
        "# merge all the documents\n",
        "merged_loader = MergedDataLoader([identity, webDocs, course_degree_df, course_unit_df, meta_guide])\n",
        "documents = merged_loader.load()\n",
        "\n",
        "print(f'We have {len(documents)} pages in total')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:09:58.846399Z",
          "start_time": "2024-06-10T16:09:55.608445Z"
        },
        "id": "5e73f1c85cf2b5f2",
        "outputId": "aae9c5bd-b385-4fe9-9e60-462bcbcf5e8a"
      },
      "id": "5e73f1c85cf2b5f2",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We have 778 pages in total\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "random_index = random.randint(0, len(documents))\n",
        "document_content = documents[random_index].page_content\n",
        "document_metadata = documents[random_index].metadata\n",
        "print(document_content,\"\\n=====================\\n\",document_metadata)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:10:01.084532Z",
          "start_time": "2024-06-10T16:10:01.076540Z"
        },
        "id": "f37b304512125353",
        "outputId": "85fc4cf1-4d91-4ae5-b006-177819d8a80b"
      },
      "id": "f37b304512125353",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The course unit code SCQ0089199, part of the Second cycle in Geophysics For Natural Risks And Resources (course degree code SC2543), titled \"NUMERICAL METHODS FOR HIGH PERFORMANCE COMPUTING\" is scheduled for the academic year 2024/25.It allocates 6.0 ECTS credits and employs a Mark type of assessment. The language of instruction is English, mandatory attendance required. The course is held by the Department of Geosciences, taught (teacher/lecturer) by CARLO JANNA in the Second semester of the 1st Year through face to face teaching lectures totaling 48 teaching hours and 102.0 hours of individual study. The course starts on 24/02/2025 and ends on 14/06/2025, with further details available at the provided course URL [https://en.didattica.unipd.it/off/2024/LM/SC/SC2543/000ZZ/SCQ0089199/N0]. The course unit can be attended as a single course unit, and can be chosen as an optional course unit, and is open to Erasmus+ and other exchange students. \n",
            " Prerequisites fot this course is: Numerical Methods for Differential Equations \n",
            " Target skills and knowledge for this course is: The present course aim at the student the basical concepts of scientific computing on high performance computers, the practical knowledge and experimentation of the main algorithms of parallel programming. During the course the most important and popular numerical kernels used in scientific programs will be deeply analyzed and studied.. Assessment criteria is Capability in designing and implementing algorithms for the numerical soultion of engineering problems on parallel computers. for this course and also examination (test) methods are :Oral discussion of the numerical project carried out during the course. Course unit contents (what strudent learns from this course) are: 1. Advanced numerical linear algebra: projection methods for non-symmetric systems (Bi-CG, QMR) and eigenproblems (Power Method, QR Method, Lanczos, DACG);2. Multigrid;3. Preconditioning techniques: ILU, approximate inverses, AMG;4. Parallel numerical analysis: basic concepts, operations and communications, data structures;5. Parallel programming paradigms: OpenMP and Message Passing Interface standards;6. Parallel implementations: sparse linear algebra kernels, iterative methods, domain decomposition. . Planned learning activities and teaching methods are : Not mentioned.. Additional notes and resource about suggested reading: Teachinh notes.Y. Saad, \"Iterative Methods for Sparse Linear Systems\", SIAM, 2003.Y. Saad, \"Numerical Methods for Large Eigenvalue problems\", SIAM, 2011.B. Chapman, G. Jost and R. van der Pas, \"Using OpenMP, Portable Shared MemoryParallel Programming\", MIT Press, 2008.P. Pacheco, \"Parallel Programming with MPI\", Morgan Kaufmann Publishers, 1997.. Textbooks for this course that suggested by teacher are(and optional supplementary readings): nan \n",
            "=====================\n",
            " {'course_unit_code': 'SCQ0089199', 'course_degree_code': 'SC2543', 'course_unit_name': 'Numerical Methods For High Performance Computing', 'course_degree_name': 'Geophysics For Natural Risks And Resources', 'course_unit_lecturer': 'CARLO JANNA'}\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Documents\n",
        "by splitting the documents into smaller chunks, we can process them more efficiently and effectively. This process is known as text splitting, and it involves dividing a large document into smaller, more manageable pieces. By splitting the documents, we can analyze and process the text in a more granular and structured manner, enabling us to extract valuable information and insights from the data. also there is some disadvantages for example my break the context or meaning of the text, but we can use some techniques to overcome this issue such as using recursive splitting or using some techniques to keep the context of the text."
      ],
      "metadata": {
        "collapsed": false,
        "id": "bd937b2abd0d617b"
      },
      "id": "bd937b2abd0d617b"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1500,\n",
        "    chunk_overlap=150,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
        ")\n",
        "\n",
        "texts = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f'We have created {len(texts)} chunks from {len(documents)} pages')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:10:17.824088Z",
          "start_time": "2024-06-10T16:10:17.026076Z"
        },
        "id": "45db1ed8f2c029ea",
        "outputId": "a2a37c1e-87c7-4131-8cb1-2f9b3d787db7"
      },
      "id": "45db1ed8f2c029ea",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "We have created 2830 chunks from 778 pages\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Embedding Model\n",
        "there is many embedding models that we can use to convert the text into vectors, for example, we can use BERT, RoBERTa, GPT-2, etc. In this example, we use the MiniLM model, which is a smaller version of the BERT model. The embedding model converts the text into dense vectors that capture the semantic meaning of the text. These vectors can be used for various natural language processing tasks, such as text classification, clustering, and similarity search."
      ],
      "metadata": {
        "collapsed": false,
        "id": "ffb0e15f75f24ded"
      },
      "id": "ffb0e15f75f24ded"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "\n",
        "embedding_model = HuggingFaceEmbeddings(model_name='all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:10:25.880406Z",
          "start_time": "2024-06-10T16:10:20.147329Z"
        },
        "id": "70ff25ca6a9a2378"
      },
      "id": "70ff25ca6a9a2378",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "When embedding a new document, the method first checks the cache for the embeddings. If the embeddings are not found, the method uses the underlying embedder to embed the documents and stores the results in the cache.\n",
        "\n",
        "* Instead of computing embeddings each time, you can retrieve them from the cache, which is often faster.\n",
        "* Reduces computational overhead and cost by not recalculating embeddings.\n",
        "\n",
        "so let's setup cache for embeddings"
      ],
      "metadata": {
        "collapsed": false,
        "id": "7c13940311e232c6"
      },
      "id": "7c13940311e232c6"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.storage import LocalFileStore\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "\n",
        "store = LocalFileStore(embedding_cache_directory)\n",
        "embedding_model = CacheBackedEmbeddings.from_bytes_store(embedding_model, store)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:10:29.475162Z",
          "start_time": "2024-06-10T16:10:29.446692Z"
        },
        "id": "cd90fc5828a3ca7e"
      },
      "id": "cd90fc5828a3ca7e",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Vector DB\n",
        "Vector databases are used to store and retrieve vectors efficiently. They are commonly used in information retrieval, recommendation systems, and clustering. Vector databases enable fast similarity search, where a query vector is compared to the vectors stored in the database to find the most similar vectors. In this example, we use the Chroma vector database, which is optimized for similarity search and retrieval tasks.\n",
        "\n",
        "Note: according to small documents size , we prefer to pass whole documents to the vector database instead of splitting them\n",
        "\n",
        "#### after first vectorize process we load saved vector database from cache in the later calls"
      ],
      "metadata": {
        "collapsed": false,
        "id": "ac719331abbab2c0"
      },
      "id": "ac719331abbab2c0"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "# vectorize chunked(split) documents (Test later)\n",
        "# vectordb = Chroma.from_documents(documents=texts, embedding=embedding_model, persist_directory=persist_directory)\n",
        "\n",
        "# check persist_directory is existed or not\n",
        "if os.path.exists(persist_directory):\n",
        "    # read from cache\n",
        "    vectordb = Chroma(\n",
        "        persist_directory= persist_directory ,\n",
        "        embedding_function=embedding_model\n",
        "    )\n",
        "else:\n",
        "    # vectorize documents without splitting\n",
        "    vectordb = Chroma.from_documents(\n",
        "        documents=documents,\n",
        "        embedding=embedding_model,\n",
        "        persist_directory=persist_directory\n",
        "    )"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:11:55.873884Z",
          "start_time": "2024-06-10T16:10:47.210394Z"
        },
        "id": "8c299c4f4f2c704f"
      },
      "id": "8c299c4f4f2c704f",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "dc936b711131057"
      },
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "<br>\n",
        "\n",
        "Let's test how much retrieved documents are similar to the query"
      ],
      "id": "dc936b711131057"
    },
    {
      "cell_type": "code",
      "source": [
        "result = vectordb.similarity_search(\n",
        "    'who is teacher in charge for Artificial intelligence course for computer science degree?',\n",
        "    k=6\n",
        ")\n",
        "\n",
        "print(f\"for query {len(result)} results found\")\n",
        "print(result[0].page_content)\n",
        "print(result[0].metadata)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:12:18.630409Z",
          "start_time": "2024-06-10T16:12:18.581408Z"
        },
        "id": "ab00ad5ae94792e0",
        "outputId": "f2b04489-72eb-4a94-897f-656f03a96732"
      },
      "id": "ab00ad5ae94792e0",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for query 6 results found\n",
            "The course unit code SCQ0093639, part of the Second cycle in Computer Science (course degree code SC2598), titled \"ARTIFICIAL INTELLIGENCE\" is scheduled for the academic year 2024/25.It allocates 6.0 ECTS credits and employs a Mark type of assessment. The language of instruction is English, mandatory attendance not required. The course is held by the Department of Mathematics, taught (teacher/lecturer) by ALESSANDRO SPERDUTI in the First semester of the 1st Year through face to face teaching lectures totaling 40 teaching hours and 85.0 hours of individual study. The course starts on 30/09/2024 and ends on 18/01/2025, with further details available at the provided course URL [https://en.didattica.unipd.it/off/2024/LM/SC/SC2598/000ZZ/SCQ0093639/N0]. The course unit can be attended as a single course unit, and can be chosen as an optional course unit, and is open to Erasmus+ and other exchange students. \n",
            " Prerequisites fot this course is: It is opportune to know basic notions of Probability Theory, Programming, and Algorithms. \n",
            " Target skills and knowledge for this course is: The course will present the main techniques of some of the most important approaches in the Artificial Intelligence field for solving difficult problems. In particular, it will present techniques for solving problems by searching, adversarial search,  knowledge representation and manipulation with and without uncertainty, decision making, and basics of machine learning, constraint-based systems, computer visione, natural language processing.It is required the development of a small optional project for a single student or a group of students.. Assessment criteria is The evaluation of the student verifies the knowledge of the student of the basic notions introduced in the course and his/her analysis capabilities. The evaluation of the optional project considers the capability of the student of finding a specific case study, and his/her ability to develop autonomously all the project activities to tackle with the case study. for this course and also examination (test) methods are :The student must overcome a written exam. Moreover, the student has the option to develop a project. Course unit contents (what strudent learns from this course) are: The structure and the topics of the course will be described in the following: - Introduction, Motivation, Intelligent Agents Architectures;- Problem Resolution and basics of Constraint-based Systems;- Adversarial Search;- Knowledge Processing by Propositional and First-order Logic;- Dealing with Uncertainty and Probabilistic Reasoning; - Basics of Machine Learning;- Basics of Computer Vision;- Basics of Natural Language Processing. . Planned learning activities and teaching methods are : The course will have frontal lessons, or online in the event of a health emergency.. Additional notes and resource about suggested reading: Additional material will be available on the course website.. Textbooks for this course that suggested by teacher are(and optional supplementary readings): Stuart Russell, Peter Norvig, Artificial Intelligence: A modern approach. --: Prentice Hall, 2010.\n",
            "{'course_degree_code': 'SC2598', 'course_degree_name': 'Computer Science', 'course_unit_code': 'SCQ0093639', 'course_unit_lecturer': 'ALESSANDRO SPERDUTI', 'course_unit_name': 'Artificial Intelligence'}\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:12:20.634465Z",
          "start_time": "2024-06-10T16:12:20.599471Z"
        },
        "id": "8bbaf1618a7cb22f",
        "outputId": "eb942350-62b6-47c7-83bf-04bea7c941db"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "result = vectordb.similarity_search(\n",
        "    'Artificial Intelligence',\n",
        "    k=6\n",
        ")\n",
        "print(f\"for query {len(result)} results found\")\n",
        "print(result[0].page_content)\n",
        "print(result[0].metadata)"
      ],
      "id": "8bbaf1618a7cb22f",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "for query 6 results found\n",
            "The course unit code SCQ0093639, part of the Second cycle in Computer Science (course degree code SC2598), titled \"ARTIFICIAL INTELLIGENCE\" is scheduled for the academic year 2024/25.It allocates 6.0 ECTS credits and employs a Mark type of assessment. The language of instruction is English, mandatory attendance not required. The course is held by the Department of Mathematics, taught (teacher/lecturer) by ALESSANDRO SPERDUTI in the First semester of the 1st Year through face to face teaching lectures totaling 40 teaching hours and 85.0 hours of individual study. The course starts on 30/09/2024 and ends on 18/01/2025, with further details available at the provided course URL [https://en.didattica.unipd.it/off/2024/LM/SC/SC2598/000ZZ/SCQ0093639/N0]. The course unit can be attended as a single course unit, and can be chosen as an optional course unit, and is open to Erasmus+ and other exchange students. \n",
            " Prerequisites fot this course is: It is opportune to know basic notions of Probability Theory, Programming, and Algorithms. \n",
            " Target skills and knowledge for this course is: The course will present the main techniques of some of the most important approaches in the Artificial Intelligence field for solving difficult problems. In particular, it will present techniques for solving problems by searching, adversarial search,  knowledge representation and manipulation with and without uncertainty, decision making, and basics of machine learning, constraint-based systems, computer visione, natural language processing.It is required the development of a small optional project for a single student or a group of students.. Assessment criteria is The evaluation of the student verifies the knowledge of the student of the basic notions introduced in the course and his/her analysis capabilities. The evaluation of the optional project considers the capability of the student of finding a specific case study, and his/her ability to develop autonomously all the project activities to tackle with the case study. for this course and also examination (test) methods are :The student must overcome a written exam. Moreover, the student has the option to develop a project. Course unit contents (what strudent learns from this course) are: The structure and the topics of the course will be described in the following: - Introduction, Motivation, Intelligent Agents Architectures;- Problem Resolution and basics of Constraint-based Systems;- Adversarial Search;- Knowledge Processing by Propositional and First-order Logic;- Dealing with Uncertainty and Probabilistic Reasoning; - Basics of Machine Learning;- Basics of Computer Vision;- Basics of Natural Language Processing. . Planned learning activities and teaching methods are : The course will have frontal lessons, or online in the event of a health emergency.. Additional notes and resource about suggested reading: Additional material will be available on the course website.. Textbooks for this course that suggested by teacher are(and optional supplementary readings): Stuart Russell, Peter Norvig, Artificial Intelligence: A modern approach. --: Prentice Hall, 2010.\n",
            "{'course_degree_code': 'SC2598', 'course_degree_name': 'Computer Science', 'course_unit_code': 'SCQ0093639', 'course_unit_lecturer': 'ALESSANDRO SPERDUTI', 'course_unit_name': 'Artificial Intelligence'}\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's load LLm model by Using Groq API\n",
        "here also we can use our fine-tuned model to generate the answer but for performance reasons, we use the Groq API\n",
        "also i have plan to use ``` https://huggingface.co/nvidia/Llama3-ChatQA-1.5-8B ``` model for this purpose"
      ],
      "metadata": {
        "collapsed": false,
        "id": "2aefd1bc8bbd709e"
      },
      "id": "2aefd1bc8bbd709e"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_groq import ChatGroq\n",
        "chat_model = ChatGroq(temperature=0, groq_api_key=groq_api_key, model_name=\"llama3-8b-8192\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:12:25.395768Z",
          "start_time": "2024-06-10T16:12:23.360422Z"
        },
        "id": "dcddbc1621086b82"
      },
      "id": "dcddbc1621086b82",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "4703e12a81b05d0f"
      },
      "cell_type": "markdown",
      "source": [
        "Let's check the model ability to answer the question (here we do not expect to know about our dataset)"
      ],
      "id": "4703e12a81b05d0f"
    },
    {
      "cell_type": "code",
      "source": [
        "qa_result = chat_model.invoke(\n",
        "    \"who is teacher in charge for Artificial intelligence course for computer science degree?\"\n",
        ")\n",
        "print(qa_result.content)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T16:12:29.313770Z",
          "start_time": "2024-06-10T16:12:27.427053Z"
        },
        "id": "be609c52d1ac8520",
        "outputId": "321347ae-6b61-4b8e-d937-a943b97a5fe6"
      },
      "id": "be609c52d1ac8520",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The teacher in charge for an Artificial Intelligence (AI) course for a Computer Science degree can vary depending on the institution, department, and faculty. However, here are some common profiles of teachers who might be in charge of an AI course:\n",
            "\n",
            "1. **Professor of Computer Science**: A professor with a background in computer science, artificial intelligence, or a related field, who has expertise in AI and machine learning.\n",
            "2. **Lecturer in AI/ML**: A lecturer who specializes in artificial intelligence, machine learning, or data science, and has a strong research background in AI-related areas.\n",
            "3. **Assistant Professor**: An assistant professor with a Ph.D. in computer science, AI, or a related field, who is actively involved in research and teaching in AI-related areas.\n",
            "4. **Senior Lecturer**: A senior lecturer with extensive teaching and research experience in AI, machine learning, or data science, who has a strong track record of publications and research grants.\n",
            "5. **Industry Expert**: An industry expert with a background in AI, machine learning, or data science, who has worked in the field and is now teaching and sharing their practical experience with students.\n",
            "\n",
            "Some common qualifications and skills that a teacher in charge of an AI course might have include:\n",
            "\n",
            "* A Ph.D. in Computer Science, AI, or a related field\n",
            "* Research experience in AI, machine learning, or data science\n",
            "* Strong programming skills in languages like Python, Java, or C++\n",
            "* Experience with AI frameworks and libraries like TensorFlow, PyTorch, or OpenCV\n",
            "* Strong teaching and communication skills\n",
            "* Familiarity with AI-related tools and technologies, such as deep learning frameworks, natural language processing, or computer vision\n",
            "\n",
            "Keep in mind that the specific qualifications and skills may vary depending on the institution, department, and faculty.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Implement Contextual Compression [Not Used in final version]\n",
        "it's a technique that compresses the context of the query into a more concise form, which can be used to retrieve relevant information from the vector database. The compressed context is then passed to the retrieval model to find the most relevant documents or vectors. This approach helps to reduce the search space and improve the accuracy of the retrieval process."
      ],
      "metadata": {
        "collapsed": false,
        "id": "6af57b30c4ad0598"
      },
      "id": "6af57b30c4ad0598"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import ContextualCompressionRetriever\n",
        "from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "\n",
        "compressor = LLMChainExtractor.from_llm(chat_model)\n",
        "compression_retriever = ContextualCompressionRetriever(\n",
        "    base_compressor=compressor,\n",
        "    base_retriever=vectordb.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T13:57:55.440361Z",
          "start_time": "2024-06-10T13:57:54.298674Z"
        },
        "id": "cf81d84de4f9df70"
      },
      "id": "cf81d84de4f9df70",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "results = compression_retriever.invoke(\n",
        "    \"who is teacher in charge for Artificial intelligence course for computer science degree?\")\n",
        "result[0]"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T13:58:22.224907Z",
          "start_time": "2024-06-10T13:57:55.443070Z"
        },
        "id": "5027042c58d9c4d4",
        "outputId": "259cf3a0-db31-427c-acbb-8504e1448042"
      },
      "id": "5027042c58d9c4d4",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Document(page_content='The course unit code SCQ0093639, part of the Second cycle in Computer Science (course degree code SC2598), titled \"ARTIFICIAL INTELLIGENCE\" is scheduled for the academic year 2024/25.It allocates 6.0 ECTS credits and employs a Mark type of assessment. The language of instruction is English, mandatory attendance not required. The course is held by the Department of Mathematics, taught (teacher/lecturer) by ALESSANDRO SPERDUTI in the First semester of the 1st Year through face to face teaching lectures totaling 40 teaching hours and 85.0 hours of individual study. The course starts on 30/09/2024 and ends on 18/01/2025, with further details available at the provided course URL [https://en.didattica.unipd.it/off/2024/LM/SC/SC2598/000ZZ/SCQ0093639/N0]. The course unit can be attended as a single course unit, and can be chosen as an optional course unit, and is open to Erasmus+ and other exchange students. \\n Prerequisites fot this course is: It is opportune to know basic notions of Probability Theory, Programming, and Algorithms. \\n Target skills and knowledge for this course is: The course will present the main techniques of some of the most important approaches in the Artificial Intelligence field for solving difficult problems. In particular, it will present techniques for solving problems by searching, adversarial search,  knowledge representation and manipulation with and without uncertainty, decision making, and basics of machine learning, constraint-based systems, computer visione, natural language processing.It is required the development of a small optional project for a single student or a group of students.. Assessment criteria is The evaluation of the student verifies the knowledge of the student of the basic notions introduced in the course and his/her analysis capabilities. The evaluation of the optional project considers the capability of the student of finding a specific case study, and his/her ability to develop autonomously all the project activities to tackle with the case study. for this course and also examination (test) methods are :The student must overcome a written exam. Moreover, the student has the option to develop a project. Course unit contents (what strudent learns from this course) are: The structure and the topics of the course will be described in the following: - Introduction, Motivation, Intelligent Agents Architectures;- Problem Resolution and basics of Constraint-based Systems;- Adversarial Search;- Knowledge Processing by Propositional and First-order Logic;- Dealing with Uncertainty and Probabilistic Reasoning; - Basics of Machine Learning;- Basics of Computer Vision;- Basics of Natural Language Processing. . Planned learning activities and teaching methods are : The course will have frontal lessons, or online in the event of a health emergency.. Additional notes and resource about suggested reading: Additional material will be available on the course website.. Textbooks for this course that suggested by teacher are(and optional supplementary readings): Stuart Russell, Peter Norvig, Artificial Intelligence: A modern approach. --: Prentice Hall, 2010.', metadata={'course_degree_code': 'SC2598', 'course_degree_name': 'Computer Science', 'course_unit_code': 'SCQ0093639', 'course_unit_name': 'Artificial Intelligence'})"
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "d7055950f74b7215"
      },
      "cell_type": "markdown",
      "source": [
        " # implement self Query [Not Used in final version]\n",
        " it's a technique that allows the model to query the vector database with the query itself. This approach is useful for retrieving documents or vectors that are similar to the query or contain relevant information. By querying the database with the query itself, the model can find documents that match the query's content or context, enabling it to retrieve relevant information more effectively."
      ],
      "id": "d7055950f74b7215"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T13:58:32.392927Z",
          "start_time": "2024-06-10T13:58:22.228856Z"
        },
        "id": "275fd86099d08774",
        "outputId": "9e8003cf-0b8c-4303-b690-784de4a24465"
      },
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import SelfQueryRetriever\n",
        "from langchain.chains.query_constructor.schema import AttributeInfo\n",
        "\n",
        "document_content_description = \"Course Unit Information\"\n",
        "\n",
        "metadata_field_info = [\n",
        "    AttributeInfo(\n",
        "        name=\"course_degree_code\",\n",
        "        description=\"Contains a unique ID for each degree course, allowing access to all course units and enabling retrieval of detailed information about the degree program using this ID.\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"course_degree_name\",\n",
        "        description=\"The name of the degree, which will appear on the final certificate issued to the student and can be used to obtain relevant information about the degree course.\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"course_unit_code\",\n",
        "        description=\"course_unit_code contain a unique code assigned to each course unit, making it recognizable within the university.\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "    AttributeInfo(\n",
        "        name=\"course_unit_lecturer\",\n",
        "        description=\"contain teacher , professor and lecturer of each course unit.\",\n",
        "        type=\"string\",\n",
        "    ),\n",
        "]\n",
        "\n",
        "self_query_retriever = SelfQueryRetriever.from_llm(\n",
        "    chat_model,\n",
        "    vectordb,\n",
        "    document_content_description,\n",
        "    metadata_field_info,\n",
        "    search_kwargs={'k': 4}\n",
        ")\n",
        "\n",
        "self_query_retriever.invoke(\"which courses lecturer is ALESSANDRO SPERDUTI?\")\n"
      ],
      "id": "275fd86099d08774",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Make Prompts template\n",
        "for getting best result we gonna follow this instruction to template message fot llm model\n",
        "* Make sure that your prompt templates are concise and easy to understand. Avoid using industry jargon or technical terms. Instead, use natural language and conversation design guidelines.\n",
        "* To give the LLM more contextual information, ask it to role play as a character, such as a sales or support representative. Then define the character’s goal. For example, include language such as, “You are a marketing executive who wants to invite major customers to a live event.”\n",
        "* Iterate on your prompt templates. Try achieving the same goal using different templates to see how the parts impact the model’s response. Get end-user feedback to see how well your prompt templates generate the desired response.\n",
        "* Choose a style, and stick to it. When you use a consistent writing style in your prompt templates, the LLM generates consistent responses. Your writing style is shaped by your word choice, intensifiers, emojis, and punctuation.\n",
        "* To help the LLM differentiate between context and instructions, create an instructions section in your prompt template. On a separate line, enter Instructions:, then surround your instructions with triple quotes (\"\"\").\n",
        "* Include direct instructions for the LLM to only generate the expected type of content. For example, if you want the LLM to draft an email, add instructions such as, “Follow these instructions strictly to generate only the message to be sent to the customer.” These instructions prevent the\n",
        "* LLM from generating a response about the process of creating content, instead of just generating the content that you want.\n",
        "Start with one of the templates in the Example Prompt Template Library, and customize it to fit your specific needs. Study the language that the templates use, especially the text related to writing style. You can use similar phrasing in your own templates."
      ],
      "metadata": {
        "collapsed": false,
        "id": "8f9fc41814ff74a7"
      },
      "id": "8f9fc41814ff74a7"
    },
    {
      "metadata": {
        "id": "a38cfe7b58d6d57b"
      },
      "cell_type": "markdown",
      "source": [
        "### QA Prompts template\n",
        "these are the prompts that we gonna use to interact with the llm model and pass context (retrieved documents for query) to it"
      ],
      "id": "a38cfe7b58d6d57b"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.prompts import SystemMessagePromptTemplate, PromptTemplate, HumanMessagePromptTemplate,MessagesPlaceholder,ChatPromptTemplate\n",
        "\n",
        "\n",
        "qa_system_prompt_template = \"\"\"\n",
        "You are Galileo the chatbot for university of Padova. Your job is to help student to find information about courses , degrees, services and general information about the university.to answer questions use following information.If you don't know an answer based on the context, say you don't know. also follow this ruels:\n",
        "\n",
        "1. If the question is to request links, please only return the source links with no answer.\n",
        "2. If you don't know the answer, don't try to make up an answer. Just say **I can't find the final answer but you may want to check the following links** and add the source links as a list.\n",
        "3. If you find the answer, write the answer in a concise way and add the list of sources that are **directly** used to derive the answer. Exclude the sources that are irrelevant to the final answer.\n",
        "\n",
        "{context}\"\"\"\n",
        "\n",
        "qa_system_prompt = SystemMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(\n",
        "        input_variables=[\"context\"], template=qa_system_prompt_template\n",
        "    )\n",
        ")\n",
        "\n",
        "qa_human_prompt_template = \"\"\"Question: {input}\n",
        "Answer:\"\"\"\n",
        "\n",
        "qa_human_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(input_variables=[\"question\"], template=qa_human_prompt_template)\n",
        ")\n",
        "\n",
        "qa_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        qa_system_prompt,\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        qa_human_prompt,\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T13:58:32.408933Z",
          "start_time": "2024-06-10T13:58:32.395931Z"
        },
        "id": "82e141496d32b6a3"
      },
      "id": "82e141496d32b6a3",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "29fc6de28c19cb46"
      },
      "cell_type": "markdown",
      "source": [
        "<br>\n",
        "<br>\n",
        "\n",
        "### Contextualize Prompt template\n",
        "prompt that use for chat history and the latest user question which might reference context in the chat history, formulate a standalone question which can be understood without the chat history. Do NOT answer the question, just reformulate it if needed and otherwise return it as is."
      ],
      "id": "29fc6de28c19cb46"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T13:58:32.424927Z",
          "start_time": "2024-06-10T13:58:32.411928Z"
        },
        "id": "18fe7392f17cb75b"
      },
      "cell_type": "code",
      "source": [
        "\n",
        "contextualize_system_prompt = (\n",
        "    \"Given a chat history and the latest user question \"\n",
        "    \"which might reference context in the chat history, \"\n",
        "    \"formulate a standalone question which can be understood \"\n",
        "    \"without the chat history. Do NOT answer the question, \"\n",
        "    \"just reformulate it if needed and otherwise return it as is.\"\n",
        ")\n",
        "\n",
        "qa_system_prompt =  SystemMessagePromptTemplate.from_template(\n",
        "    contextualize_system_prompt\n",
        ")\n",
        "\n",
        "qa_human_prompt_template = \"\"\"Question: {input}\n",
        "Answer:\"\"\"\n",
        "\n",
        "qa_human_prompt = HumanMessagePromptTemplate(\n",
        "    prompt=PromptTemplate(input_variables=[\"question\"], template=qa_human_prompt_template)\n",
        ")\n",
        "\n",
        "contextualize_q_prompt = ChatPromptTemplate.from_messages(\n",
        "    [\n",
        "        qa_system_prompt,\n",
        "        MessagesPlaceholder(\"chat_history\"),\n",
        "        qa_human_prompt,\n",
        "    ]\n",
        ")\n"
      ],
      "id": "18fe7392f17cb75b",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "4b05806bc6a68490"
      },
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "## Setup Chain of thought\n",
        "\n",
        "Similarity:\n",
        "In the context of data retrieval from vector databases, the \"similarity\" search type focuses on finding documents or vectors that are most similar to a given query. This approach calculates the similarity between the query vector and vectors stored in the database using mathematical metrics such as cosine similarity or Euclidean distance. Documents with higher similarity scores are considered more relevant and are retrieved as search results. The \"similarity\" search type is commonly used for tasks like document retrieval, recommendation systems, and information retrieval.\n",
        "\n",
        "Similarity Score Threshold:\n",
        "The \"similarity_score_threshold\" search type is a refinement of the basic similarity search method. In addition to calculating the similarity between the query vector and database vectors, this approach applies a threshold value to filter out search results based on their similarity scores. Only documents or vectors with similarity scores above the specified threshold are returned as search results. By setting an appropriate threshold, users can control the level of relevance and precision in the retrieved results. This search type is useful in scenarios where a certain level of similarity is required for result inclusion, such as in content recommendation systems or search engines.\n",
        "\n",
        "Maximal Marginal Relevance (MMR):\n",
        "Maximal Marginal Relevance (MMR) is a search type that focuses on diversifying search results by balancing relevance and diversity. Unlike traditional similarity-based approaches that prioritize documents with high similarity scores, MMR considers both the relevance of a document to the query and its dissimilarity to already retrieved documents. MMR aims to provide a diverse set of search results that cover a wide range of relevant topics or perspectives, making it particularly useful in tasks like information retrieval, summarization, and recommendation systems where diversity in results is desired."
      ],
      "id": "4b05806bc6a68490"
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
        "from langchain.chains.history_aware_retriever import create_history_aware_retriever\n",
        "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
        "from langchain.chains import (create_retrieval_chain)\n",
        "from langchain_core.chat_history import BaseChatMessageHistory\n",
        "from langchain_community.chat_message_histories import ChatMessageHistory\n",
        "from langchain_core.runnables import ConfigurableFieldSpec\n",
        "\n",
        "retriever = vectordb.as_retriever(\n",
        "    search_type=\"similarity\",\n",
        "    search_kwargs={'k': 4}\n",
        ")\n",
        "\n",
        "history_aware_retriever = create_history_aware_retriever(chat_model, retriever, contextualize_q_prompt)\n",
        "question_answer_chain = create_stuff_documents_chain(chat_model, qa_prompt)\n",
        "rag_chain = create_retrieval_chain(history_aware_retriever, question_answer_chain)\n",
        "\n",
        "\n",
        "# chat history store for manage session history\n",
        "store = {}\n",
        "\n",
        "def get_session_history(user_id: str, conversation_id: str) -> BaseChatMessageHistory:\n",
        "    if user_id not in store:\n",
        "        store[user_id] = ChatMessageHistory()\n",
        "    return store[user_id]\n",
        "\n",
        "\n",
        "conversational_rag_chain = RunnableWithMessageHistory(\n",
        "    rag_chain,\n",
        "    get_session_history,\n",
        "    input_messages_key=\"input\",\n",
        "    history_messages_key=\"chat_history\",\n",
        "    output_messages_key=\"answer\",\n",
        "    history_factory_config=[\n",
        "        ConfigurableFieldSpec(\n",
        "            id=\"user_id\",\n",
        "            annotation=str,\n",
        "            name=\"User ID\",\n",
        "            description=\"Unique identifier for the user.\",\n",
        "            default=\"\",\n",
        "            is_shared=True,\n",
        "        ),\n",
        "        ConfigurableFieldSpec(\n",
        "            id=\"conversation_id\",\n",
        "            annotation=str,\n",
        "            name=\"Conversation ID\",\n",
        "            description=\"Unique identifier for the conversation.\",\n",
        "            default=\"\",\n",
        "            is_shared=True,\n",
        "        ),\n",
        "    ],\n",
        ")\n",
        "\n",
        "\n",
        "def execute_conversation(input_text: str, session_id: str = \"default\"):\n",
        "    var = conversational_rag_chain.invoke(\n",
        "        {\"input\":input_text},\n",
        "        config={\"configurable\": {\"user_id\": session_id, \"conversation_id\": \"0\"}},\n",
        "    )\n",
        "    return var.get(\"answer\")"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T13:58:32.488925Z",
          "start_time": "2024-06-10T13:58:32.427926Z"
        },
        "id": "75f33576dbd35867"
      },
      "id": "75f33576dbd35867",
      "outputs": [],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "491c6766ae1ef128"
      },
      "cell_type": "markdown",
      "source": [
        "you can check chat history for each user in real-time by running this code"
      ],
      "id": "491c6766ae1ef128"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T14:05:12.503639Z",
          "start_time": "2024-06-10T14:05:12.482639Z"
        },
        "id": "b4d9603138540753",
        "outputId": "d2eb45d5-84a7-4980-95c7-e5a2e3e520cc"
      },
      "cell_type": "code",
      "source": [
        "store"
      ],
      "id": "b4d9603138540753",
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'default': InMemoryChatMessageHistory(messages=[HumanMessage(content='can you provide url for the course unit Artificial intelligence for computer science degree?'), AIMessage(content='The URL for the course unit \"Artificial Intelligence\" for the Computer Science degree is:\\n\\nhttps://en.didattica.unipd.it/off/2024/LM/SC/SC2598/000ZZ/SCQ0093639/N0'), HumanMessage(content='give me the web page of deep learning?'), AIMessage(content='Here are the URLs for the Deep Learning courses:\\n\\n1. SCP9087561, part of the Second cycle in Cybersecurity (course degree code SC2542):\\nhttps://en.didattica.unipd.it/off/2024/LM/SC/SC2542/000ZZ/SCP9087561/DISPARI\\n\\n2. SCP9087561, part of the Second cycle in Cybersecurity (course degree code SC2542):\\nhttps://en.didattica.unipd.it/off/2024/LM/SC/SC2542/000ZZ/SCP9087561/PARI\\n\\n3. SCP9087561, part of the Second cycle in Computer Science (course degree code SC2598):\\nhttps://en.didattica.unipd.it/off/2024/LM/SC/SC2598/000ZZ/SCP9087561/DISPARI\\n\\n4. SCP9087561, part of the Second cycle in Computer Science (course degree code SC2598):\\nhttps://en.didattica.unipd.it/off/2024/LM/SC/SC2598/000ZZ/SCP9087561/PARI'), HumanMessage(content='which courses does ALESSANDRO SPERDUTI teach? provide their course link'), AIMessage(content='According to the provided information, ALESSANDRO SPERDUTI teaches the course:\\n\\n* SCP9087561, part of the Second cycle in Cybersecurity (course degree code SC2542), titled \"DEEP LEARNING (Ult. numero di matricola pari)\"\\n\\nThe course link is:\\n\\nhttps://en.didattica.unipd.it/off/2024/LM/SC/SC2542/000ZZ/SCP9087561/PARI'), HumanMessage(content='can you provide course url address for this course?'), AIMessage(content='Here are the course URLs:\\n\\n1. SCQ0093639, part of the Second cycle in Computer Science (course degree code SC2598), titled \"ARTIFICIAL INTELLIGENCE\":\\nhttps://en.didattica.unipd.it/off/2024/LM/SC/SC2598/000ZZ/SCQ0093639/N0\\n\\n2. SCQ3104093, part of the Second cycle in Cybersecurity (course degree code SC2542), titled \"ADVERSARIAL MACHINE LEARNING\":\\nhttps://en.didattica.unipd.it/off/2023/LM/SC/SC2542/000ZZ/SCQ3104093/N0\\n\\n3. SC01111799, part of the Second cycle in Computer Science (course degree code SC2598), titled \"DATA MINING\":\\nhttps://en.didattica.unipd.it/off/2024/LM/SC/SC2598/000ZZ/SC01111799/N0\\n\\n4. SCP8082660, part of the Second cycle in Cybersecurity (course degree code SC2542), titled \"MACHINE LEARNING (A)\":\\nhttps://en.didattica.unipd.it/off/2024/LM/SC/SC2542/000ZZ/SCP8082660/G2GR1')]),\n",
              " '285ff248-4cfa-4f86-9731-ebf47cd505ce': InMemoryChatMessageHistory(messages=[HumanMessage(content='what is you name ?'), AIMessage(content=\"My name is Galileo, and I'm the official Virtual Assistant of the University of Padua (UNIPD). I'm here to assist you with any questions or concerns you may have about the university and its courses.\"), HumanMessage(content='what was you job before university of padova ?'), AIMessage(content=\"I'm just Galileo, the official Virtual Assistant of the University of Padua (UNIPD). I don't have a job before the University of Padova, as I was created specifically for this role. I'm a new AI model designed to assist students and provide information about the university and its courses.\"), HumanMessage(content='who created you ?'), AIMessage(content='I was created by the University of Padua (UNIPD) to assist students and provide information about the university and its courses.'), HumanMessage(content='who is the teacher of Natural language processing course for computer science ?'), AIMessage(content=\"I'm not aware of the specific information about the teacher of the Natural Language Processing course for Computer Science. However, I can suggest checking the course website or contacting the department of Computer Science at the University of Padua for more information.\")]),\n",
              " '2bee8cb1-50af-4c4c-b974-6fe56b5d347c': InMemoryChatMessageHistory(messages=[HumanMessage(content='who is the teacher of Natural language processing course for computer science ?'), AIMessage(content='The teacher of the Natural Language Processing course for Computer Science is Giovanni Da San Martino.')])}"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Let's sampling\n"
      ],
      "metadata": {
        "collapsed": false,
        "id": "744eb872a5e8b845"
      },
      "id": "744eb872a5e8b845"
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T13:58:46.502988Z",
          "start_time": "2024-06-10T13:58:32.491926Z"
        },
        "id": "10799a9d56c1d72f",
        "outputId": "ce956c43-a60d-47f4-b216-0715fe2ac618"
      },
      "cell_type": "code",
      "source": [
        "print(execute_conversation(\"can you provide url for the course unit Artificial intelligence for computer science degree?\"))"
      ],
      "id": "10799a9d56c1d72f",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The URL for the course unit \"Artificial Intelligence\" for the Computer Science degree is:\n",
            "\n",
            "https://en.didattica.unipd.it/off/2024/LM/SC/SC2598/000ZZ/SCQ0093639/N0\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T13:59:16.514169Z",
          "start_time": "2024-06-10T13:59:14.457080Z"
        },
        "id": "585baaf90d83c651",
        "outputId": "78c799b4-68e1-46b4-9e42-fcd38b256919"
      },
      "cell_type": "code",
      "source": [
        "print(execute_conversation(\"give me the web page of deep learning?\"))"
      ],
      "id": "585baaf90d83c651",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are the URLs for the Deep Learning courses:\n",
            "\n",
            "1. SCP9087561, part of the Second cycle in Cybersecurity (course degree code SC2542):\n",
            "https://en.didattica.unipd.it/off/2024/LM/SC/SC2542/000ZZ/SCP9087561/DISPARI\n",
            "\n",
            "2. SCP9087561, part of the Second cycle in Cybersecurity (course degree code SC2542):\n",
            "https://en.didattica.unipd.it/off/2024/LM/SC/SC2542/000ZZ/SCP9087561/PARI\n",
            "\n",
            "3. SCP9087561, part of the Second cycle in Computer Science (course degree code SC2598):\n",
            "https://en.didattica.unipd.it/off/2024/LM/SC/SC2598/000ZZ/SCP9087561/DISPARI\n",
            "\n",
            "4. SCP9087561, part of the Second cycle in Computer Science (course degree code SC2598):\n",
            "https://en.didattica.unipd.it/off/2024/LM/SC/SC2598/000ZZ/SCP9087561/PARI\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(execute_conversation(\"which courses does ALESSANDRO SPERDUTI teach? provide their course link\"))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T13:59:22.474013Z",
          "start_time": "2024-06-10T13:59:19.943492Z"
        },
        "id": "b8a7dfbd7fff0a66",
        "outputId": "39e42e31-7cc6-4d90-bd0e-74a5e942a15a"
      },
      "id": "b8a7dfbd7fff0a66",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "According to the provided information, ALESSANDRO SPERDUTI teaches the course:\n",
            "\n",
            "* SCP9087561, part of the Second cycle in Cybersecurity (course degree code SC2542), titled \"DEEP LEARNING (Ult. numero di matricola pari)\"\n",
            "\n",
            "The course link is:\n",
            "\n",
            "https://en.didattica.unipd.it/off/2024/LM/SC/SC2542/000ZZ/SCP9087561/PARI\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T14:00:13.191980Z",
          "start_time": "2024-06-10T14:00:10.173594Z"
        },
        "id": "a851386d55f0da36",
        "outputId": "dc4acc2d-7c15-47b8-cca3-e89785833b60"
      },
      "cell_type": "code",
      "source": [
        "print(execute_conversation(\"can you provide course url address for this course?\"))"
      ],
      "id": "a851386d55f0da36",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here are the course URLs:\n",
            "\n",
            "1. SCQ0093639, part of the Second cycle in Computer Science (course degree code SC2598), titled \"ARTIFICIAL INTELLIGENCE\":\n",
            "https://en.didattica.unipd.it/off/2024/LM/SC/SC2598/000ZZ/SCQ0093639/N0\n",
            "\n",
            "2. SCQ3104093, part of the Second cycle in Cybersecurity (course degree code SC2542), titled \"ADVERSARIAL MACHINE LEARNING\":\n",
            "https://en.didattica.unipd.it/off/2023/LM/SC/SC2542/000ZZ/SCQ3104093/N0\n",
            "\n",
            "3. SC01111799, part of the Second cycle in Computer Science (course degree code SC2598), titled \"DATA MINING\":\n",
            "https://en.didattica.unipd.it/off/2024/LM/SC/SC2598/000ZZ/SC01111799/N0\n",
            "\n",
            "4. SCP8082660, part of the Second cycle in Cybersecurity (course degree code SC2542), titled \"MACHINE LEARNING (A)\":\n",
            "https://en.didattica.unipd.it/off/2024/LM/SC/SC2542/000ZZ/SCP8082660/G2GR1\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(execute_conversation(\"how is teacher in charge for mentioned course unit?\"))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T11:45:19.900165Z",
          "start_time": "2024-06-10T11:45:19.311147Z"
        },
        "id": "fe3e6fc29719a6dc",
        "outputId": "e0475593-8f9f-4dae-c56f-772b37a02d3e"
      },
      "id": "fe3e6fc29719a6dc",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "how is teacher in charge for mentioned course unit?\n",
            "content='According to the University of Padova\\'s course catalog, the teacher in charge for the course unit \"Artificial Intelligence\" is Professor Roberto Basili.\\n\\nPlease note that the information may be subject to change, and it\\'s always best to check with the university\\'s course catalog or the department for the most up-to-date information.\\n\\nSources:\\n* University of Padova Course Catalog\\n\\nPlease let me know if you need any further assistance!' response_metadata={'token_usage': {'completion_time': 0.068036046, 'completion_tokens': 86, 'prompt_time': 0.096020922, 'prompt_tokens': 371, 'queue_time': None, 'total_time': 0.164056968, 'total_tokens': 457}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_873a560973', 'finish_reason': 'stop', 'logprobs': None} id='run-4f0900fd-7770-4ccf-ac3f-4ead0f922caa-0'\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "print(execute_conversation(\"does this course have project?\"))"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T11:46:58.563422Z",
          "start_time": "2024-06-10T11:46:57.891558Z"
        },
        "id": "bbca39213d5d76a4",
        "outputId": "54422358-dbd3-484a-9c78-a3bbc046f890"
      },
      "id": "bbca39213d5d76a4",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "does this course have project?\n",
            "content='According to the University of Padova\\'s course catalog, the course unit \"Artificial Intelligence\" does include a project component.\\n\\nStudents are required to work on a project that applies the concepts and techniques learned throughout the course to a real-world problem or scenario. The project is an essential part of the course and is assessed as part of the final grade.\\n\\nPlease note that the specific requirements and details of the project may vary from year to year, and it\\'s always best to check with the course instructor or the university\\'s course catalog for the most up-to-date information.\\n\\nSources:\\n* University of Padova Course Catalog\\n\\nPlease let me know if you need any further assistance!' response_metadata={'token_usage': {'completion_time': 0.106304228, 'completion_tokens': 134, 'prompt_time': 0.122713074, 'prompt_tokens': 473, 'queue_time': None, 'total_time': 0.229017302, 'total_tokens': 607}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_179b0f92c9', 'finish_reason': 'stop', 'logprobs': None} id='run-a6d1eb11-2c17-4c55-9154-3eccaf18b004-0'\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "metadata": {
        "id": "d55389d4e1f99ff0"
      },
      "cell_type": "markdown",
      "source": [
        "## Gradio\n",
        "it's a simple way to create a web-based interface for your model. You can define the input and output types of your model, and Gradio will automatically create an interactive web interface for it. You can customize the interface with different input types, output types, and styling options to suit your needs. Gradio also provides a shareable link to your interface, making it easy to share your model with others."
      ],
      "id": "d55389d4e1f99ff0"
    },
    {
      "cell_type": "code",
      "source": [
        "from uuid import uuid4\n",
        "import gradio as gr\n",
        "\n",
        "\n",
        "# generate session id for each load of webpage to keep the history of conversation for each user\n",
        "def store_message(message: str, history):\n",
        "    if not history:\n",
        "        uuid = str(uuid4())\n",
        "        history = [uuid]\n",
        "    output = execute_conversation(message, history[-1])\n",
        "    return output, history\n",
        "\n",
        "demo = gr.Interface(\n",
        "    fn=store_message,\n",
        "    inputs=[\"text\", gr.State(value=[])],\n",
        "    outputs=[\"text\", gr.State()]\n",
        ")\n",
        "\n",
        "demo.launch(share=True)"
      ],
      "metadata": {
        "ExecuteTime": {
          "end_time": "2024-06-10T14:20:23.278024Z",
          "start_time": "2024-06-10T14:20:10.530097Z"
        },
        "id": "d9045e7e4ef916d6",
        "outputId": "1f46a249-cbd9-4a7f-c964-f358fea0cf03"
      },
      "id": "d9045e7e4ef916d6",
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running on local URL:  http://127.0.0.1:7863\n",
            "\n",
            "Could not create share link. Please check your internet connection or our status page: https://status.gradio.app.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024/06/10 16:20:23 [W] [service.go:132] login to server failed: dial tcp 44.237.78.176:7000: i/o timeout\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": []
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Speech to Text and Text to Speech"
      ],
      "metadata": {
        "id": "VFOW2RWc0c0y"
      },
      "id": "VFOW2RWc0c0y"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.cloud import texttospeech\n",
        "import sounddevice as sd\n",
        "import soundfile as sf\n",
        "import speech_recognition as sr"
      ],
      "metadata": {
        "id": "kCnapvH80Shx"
      },
      "id": "kCnapvH80Shx",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set up Google Cloud credentials\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = 'secret.json'\n",
        "\n",
        "# Initialize the recognizer\n",
        "recognizer = sr.Recognizer()"
      ],
      "metadata": {
        "id": "X9oWYeZg0SY8"
      },
      "id": "X9oWYeZg0SY8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speak(text):\n",
        "    client = texttospeech.TextToSpeechClient()\n",
        "\n",
        "    input_text = texttospeech.SynthesisInput(text=text)\n",
        "\n",
        "    # Select the type of voice\n",
        "    voice = texttospeech.VoiceSelectionParams(\n",
        "        language_code=\"en-US\",\n",
        "        name=\"en-US-Standard-J\",  # Male voice\n",
        "        ssml_gender=texttospeech.SsmlVoiceGender.MALE\n",
        "    )\n",
        "\n",
        "    # Select the audio configuration\n",
        "    audio_config = texttospeech.AudioConfig(\n",
        "        audio_encoding=texttospeech.AudioEncoding.LINEAR16\n",
        "    )\n",
        "\n",
        "    # Perform the text-to-speech request\n",
        "    response = client.synthesize_speech(\n",
        "        input=input_text, voice=voice, audio_config=audio_config\n",
        "    )\n",
        "\n",
        "    # Save the response to an audio file\n",
        "    with open(\"output.wav\", \"wb\") as out:\n",
        "        out.write(response.audio_content)\n",
        "\n",
        "    # Play the audio file\n",
        "    data, fs = sf.read(\"output.wav\", dtype='float32')\n",
        "    sd.play(data, fs)\n",
        "    sd.wait()  # Wait until the sound has finished playing\n",
        "\n",
        "    os.remove(\"output.wav\")"
      ],
      "metadata": {
        "id": "YvQccR0s0SQM"
      },
      "id": "YvQccR0s0SQM",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def recognize_speech_from_mic():\n",
        "    with sr.Microphone() as source:\n",
        "        print(\"Adjusting for ambient noise, please wait...\")\n",
        "        recognizer.adjust_for_ambient_noise(source, duration=5)\n",
        "        print(\"Listening...\")\n",
        "        audio = recognizer.listen(source)\n",
        "\n",
        "        try:\n",
        "            print(\"Recognizing speech...\")\n",
        "            text = recognizer.recognize_google(audio)\n",
        "            print(f\"You said: {text}\")\n",
        "            return text\n",
        "        except sr.UnknownValueError:\n",
        "            print(\"Sorry, I did not understand that.\")\n",
        "        except sr.RequestError:\n",
        "            print(\"Sorry, there was an issue with the speech recognition service.\")\n",
        "        return None"
      ],
      "metadata": {
        "id": "EYLIZFv70SHf"
      },
      "id": "EYLIZFv70SHf",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    counter = 0\n",
        "    while True:\n",
        "        # Text-to-Speech example\n",
        "        init_text = \"Hello, My name is Galileo, I am the official chatbot of the University of Padova, how can I help you?\"\n",
        "        text= \"Is There anything else that I can assist you with?\"\n",
        "\n",
        "\n",
        "        if counter == 0:\n",
        "            print(f\"Saying: {init_text}\")\n",
        "            speak(init_text)\n",
        "        else:\n",
        "            print(f\"Saying: {text}\")\n",
        "            speak(text)\n",
        "\n",
        "\n",
        "        # Speech-to-Text example\n",
        "        recognized_text = recognize_speech_from_mic()\n",
        "        if recognized_text:\n",
        "            if \"finish\" in recognized_text.lower():\n",
        "                speak(\"It was Galileo's pleasure to assist you!\")\n",
        "                break\n",
        "            print(f\"Student prompt: \\n {recognized_text}\")\n",
        "            Galileo = execute_conversation(recognized_text)\n",
        "            print(\"Galileo: \\n\")\n",
        "            print(Galileo)\n",
        "            speak(Galileo)\n",
        "            counter +=1"
      ],
      "metadata": {
        "id": "d4d8fSU60R-Q"
      },
      "id": "d4d8fSU60R-Q",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}